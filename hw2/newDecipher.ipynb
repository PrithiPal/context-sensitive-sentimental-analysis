{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import ngram\n",
    "from ngram import *\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "import numpy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats\n",
    "\n",
    "def find_mappings(ciphertext, plaintext):\n",
    "    mappings = defaultdict(dict)\n",
    "    hypotheses = defaultdict(dict)\n",
    "    \n",
    "    for symbol in ciphertext['vocab']:\n",
    "        for letter in plaintext['vocab']:\n",
    "            hypotheses[symbol][letter] = abs(math.log((ciphertext['relative_freq'][symbol]/plaintext['relative_freq'][letter])))\n",
    "    \n",
    "    for sym in hypotheses.keys():\n",
    "        winner = sorted(hypotheses[sym].items(), key=lambda kv: kv[1])\n",
    "        mappings[sym] = winner[1][0]\n",
    "    \n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¢', 'J', '∏', '^', 'H', '—', '∞', 'O', '§', '≈', 'Q', 'M', 'π', 'I', 'S', 'V', 'G', '‘', '£', 'X', 'L', 'F', '√', '∫', '+', 'æ', 'D', 'µ', '∆', 'P', '\\\\', 'T', 'Ã', 'E', 'À', 'B', '–', 'Z', 'R', 'y', '/', 'W', '∑', 'u', 'A', 'j', 'Ω', 'ƒ', 'K', 'Ç', 'N', 'º', '“', '•']\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "\n",
    "\n",
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "\n",
    "mapping = find_mappings(cipher_desc, plaintxt_desc)\n",
    "\n",
    "english_text = []\n",
    "for symbol in cipher_desc['content']:\n",
    "    english_text.append(mapping[symbol])\n",
    "decipherment = ('').join(english_text)\n",
    "#print(decipherment)\n",
    "print(cipher_desc['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = []; \n",
    "symbol_relFreq = []; \n",
    "for x, y in cipher_desc[\"relative_freq\"].items():\n",
    "    symbol_list.append(x)\n",
    "    symbol_relFreq.append(y)\n",
    "    \n",
    "index_names = {}\n",
    "for i in range(54):\n",
    "    index_names[i] = symbol_list[i]\n",
    "    \n",
    "test_data = numpy.ones((54,26))\n",
    "df = pd.DataFrame(test_data, columns = plaintxt_desc['vocab'])\n",
    "df=df.rename(index = index_names )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "freq_dict=[ (k,v) for k,v in zip(cipher_desc['frequencies'].keys(),cipher_desc['frequencies'].values())]\n",
    "sorted_freq_dict=sorted(freq_dict, key=lambda x:max([v[1] for v in freq_dict])-x[1])\n",
    "sorted_symbols=[s[0] for s in sorted_freq_dict]\n",
    "\n",
    "lm = ngram.LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J\n",
      "∏\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'....................................................o................................................o.............................................................o........................................................................o...........................................................................................................................................................................'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_bitstring(F,cipher_text) : \n",
    "    f=F[0]\n",
    "    INITIAL_BS=['o' if f == t else '.' for t in cipher_text]\n",
    "    for f in F[1:] :\n",
    "        print(f)\n",
    "        \n",
    "    FINAL_BS=INITIAL_BS\n",
    "    \n",
    "    return \"\".join(FINAL_BS)\n",
    "convert_to_bitstring(cipher_desc['vocab'][:3],\"\".join(cipher_desc['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satisfy_ext_limits(phi_obj,nkeep) : \n",
    "    \n",
    "   # print(phi_obj)\n",
    "    l = dict([(i[0],0) for i in phi_obj])\n",
    "    for elem in phi_obj : \n",
    "        l[str(elem[0])]+=1\n",
    "   \n",
    "    n_lengths=list(filter(lambda x:x>nkeep,list(l.values())))\n",
    "   \n",
    "    if n_lengths == [] : \n",
    "        return True \n",
    "    else : \n",
    "        return False\n",
    "    \n",
    "def score_partial_hypothesis(cipher, phi,lm) :\n",
    "   \n",
    "    reverse_phi= dict([(i[1],i[0]) for i in phi ])\n",
    "    f_phi_list = [i[1] for i in phi]\n",
    "    \n",
    "    deciphered_tokens=[]\n",
    "    overall_score=0\n",
    "    for f in cipher : \n",
    "       \n",
    "        if f in f_phi_list : \n",
    "            deciphered_tokens.append(reverse_phi[str(f)])\n",
    "        else : \n",
    "            deciphered_tokens.append(\"_\")  \n",
    "        \n",
    "    \n",
    "    arg1 = \"\".join(deciphered_tokens)\n",
    "    #print('arg1 = ',arg1)\n",
    "    score = lm.score_seq(arg1)     \n",
    "    return score\n",
    "\n",
    "def hist_prune(H,nkeep) : \n",
    "\n",
    "    scores = [float(i[1]) for i in H]\n",
    "    scores_s = sorted(H,key=lambda x:x[1])\n",
    "    #print(scores_s)\n",
    "    return scores_s[-1]\n",
    "\n",
    "\n",
    "def score_beam(hs,real_phi) : \n",
    "    phi = hs[0][0]\n",
    "    score=0\n",
    "    for p in phi : \n",
    "        if p in real_phi : \n",
    "            score=score+1\n",
    "    \n",
    "    correct_ratio = score/len(phi)\n",
    "    return correct_ratio\n",
    "\n",
    "def convert_to_bitstring(f,cipher_text) : \n",
    "    return \"\".join(['o' if f == t else '.' for t in cipher_text])\n",
    "\n",
    "def calculate_maximum_context_score(cipher_text,f,W) : \n",
    "    bitstring = convert_to_bitstring(f,cipher_text)\n",
    "  #  print(bitstring)\n",
    "    contagious_o = re.findall(r'[o]+',bitstring)\n",
    "    contagious_lenghts = [len(i) for i in contagious_o]\n",
    "   # print(contagious_lenghts)\n",
    "    N=6\n",
    "    max_context=[float(len(list(filter(lambda x:x==i,contagious_lenghts)))) for i in range(N)]\n",
    "    term=np.multiply(W,max_context)\n",
    "    return sum(term)\n",
    "        \n",
    "    \n",
    "## hs=[( (A,A), (A,A) ... )]\n",
    "## W=[a,a,a,a,a,a]\n",
    "## cipher_text = \"aaaaaa\"\n",
    "def sort_by_new_extension_order(cipher_text,F,W) : \n",
    "    MC_SCORE=[]\n",
    "    \n",
    "    for f in F : \n",
    "        \n",
    "        score=calculate_maximum_context_score(cipher_text,f,W)\n",
    "        MC_SCORE.append((f,score))\n",
    "    \n",
    "    \n",
    "    return list(reversed(sorted(MC_SCORE,key=lambda x:x[1])))\n",
    "    \n",
    "    \n",
    "def get_sorted_syms(x1,x2) : \n",
    "    freq_dict=[ (k,v) for k,v in zip(x2['frequencies'].keys(),x2['frequencies'].values())]\n",
    "    sorted_freq_dict=sorted(freq_dict, key=lambda x:max([v[1] for v in freq_dict])-x[1])\n",
    "    sorted_symbols=[s[0] for s in sorted_freq_dict]\n",
    "    return sorted_symbols\n",
    "\n",
    "\n",
    "#SAMPLE_PHI=[('', ''), ('e', '—'), ('e', 'º'), ('u', 'B'), ('v', 'R')]\n",
    "#satisfy_ext_limits(SAMPLE_PHI,3)\n",
    "\n",
    "\n",
    "#PHI=[('b','B')]\n",
    "#score_partial_hypothesis(\"BURGER\",PHI,lm)\n",
    "\n",
    "#SAMPLE=[([('', ''), ('e', 'O'), ('h', 'T')], -32.71637948), ([('', ''), ('e', 'O'), ('s', 'T')], -21.396480099999998), ([('', ''), ('e', 'O'), ('o', 'T')], -39.44501403), ([('', ''), ('e', 'O'), ('j', 'T')], -33.47798432999999), ([('', ''), ('e', 'O'), ('d', 'T')], -20.987173), ([('', ''), ('e', 'O'), ('v', 'T')], -30.673667710000004), ([('', ''), ('e', 'O'), ('g', 'T')], -29.781602661000004), ([('', ''), ('e', 'O'), ('f', 'T')], -28.604963550999997), ([('', ''), ('e', 'O'), ('a', 'T')], -29.75088907), ([('', ''), ('e', 'O'), ('r', 'T')], -24.553558436), ([('', ''), ('e', 'O'), ('x', 'T')], -32.67641992), ([('', ''), ('e', 'O'), ('m', 'T')], -30.1644232), ([('', ''), ('e', 'O'), ('t', 'T')], -29.95256448), ([('', ''), ('e', 'O'), ('b', 'T')], -26.972342800000003), ([('', ''), ('e', 'O'), ('u', 'T')], -34.10374856), ([('', ''), ('e', 'O'), ('c', 'T')], -33.261454670000006), ([('', ''), ('e', 'O'), ('p', 'T')], -29.9686529), ([('', ''), ('e', 'O'), ('q', 'T')], -38.0978153), ([('', ''), ('e', 'O'), ('w', 'T')], -31.314459720000002), ([('', ''), ('e', 'O'), ('k', 'T')], -29.489249459999996), ([('', ''), ('e', 'O'), ('n', 'T')], -27.4332253), ([('', ''), ('e', 'O'), ('z', 'T')], -31.70670717), ([('', ''), ('e', 'O'), ('i', 'T')], -30.30622924), ([('', ''), ('e', 'O'), ('y', 'T')], -32.38038479), ([('', ''), ('e', 'O'), ('l', 'T')], -26.465809439999997)]\n",
    "#hist_prune(SAMPLE,1)\n",
    "\n",
    "#SAMPLE= [([('', ''), ('x', 'E'), ('i', 'T'), ('a', 'N'), ('s', 'A'), ('m', 'O'), ('e', 'R'), ('j', 'U'), ('n', 'B'), ('t', 'D'), ('o', 'P'), ('r', 'I'), ('u', 'H'), ('g', 'L'), ('f', 'S'), ('q', 'Y'), ('h', 'X'), ('y', 'G'), ('b', 'W'), ('p', 'V'), ('d', 'M')], -291.5569235510001)]\n",
    "\n",
    "#CIPHER=\"\".join(cipher_desc['content'])\n",
    "#W=[1,1,1,1,2,3]\n",
    "#print(sort_by_new_extension_order(CIPHER,cipher_desc['vocab'],W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper func for debugging\n",
    "# Change the 'isverbose' to True to print\n",
    "def printifverbose(text, isverbose=False):\n",
    "    if isverbose:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def beam_search(ext_order, ext_limits,Vf,nkeep,cipher_text):\n",
    "    # FOR 'BURGER' EXAMPLE:\n",
    "    # ext_order: ['R', 'B', 'U', 'G', 'E']\n",
    "    # Vf: ['U', 'E', 'B', 'G', 'R']\n",
    "    # cipher_text: \"burger\"\n",
    "    \n",
    "    printifverbose(str(\"==startbeamsearch==\").upper())\n",
    "    \n",
    "    Hs = []\n",
    "    Ht = []\n",
    "    # Hs and Ht will be of format '[phi, score]' \n",
    "    # which is '[list, float]'\n",
    "    # [([('', '')], 0)]\n",
    "    cardinality = 0\n",
    "    Hs.append(([('','')],0))\n",
    "    #print(Hs[0])\n",
    "    Ve = plaintxt_desc['vocab']  # Ve: ['k', 'z', 'n', 's', 'o', 'q', 'd', 'c', 'i', 't', 'w', 'p', 'h', 'g', 'm', 'l', 'v', 'a', 'e', 'y', 'b', 'x', 'f', 'r', 'j', 'u']\n",
    "    new_phi=[]\n",
    "    \n",
    "    printifverbose(\"len(Vf): \" + str(len(Vf)))\n",
    "    \n",
    "    while cardinality < len(Vf):  #line5\n",
    "        printifverbose(\"\\t--beginwhile--\")\n",
    "\n",
    "        f = ext_order[cardinality]  #line6\n",
    "        printifverbose(\"\\tCurrent cipher character (f): \" + f + \"\\n\")\n",
    "\n",
    "        # Hs is in:\n",
    "        # [([('', '')], 0)]\n",
    "        for h in Hs:  #line7a\n",
    "            printifverbose(\"\\t\\t--beginOuterloop--\")\n",
    "            \n",
    "            phi=h[0]  #line7b\n",
    "\n",
    "            printifverbose(\"\\t\\tlen(Ve):\" + str(len(Ve)) + \"\\n\")\n",
    "            for e in Ve:  #line8\n",
    "                printifverbose(\"\\t\\t\\t--beginInnerloop--\")\n",
    "                \n",
    "                printifverbose(\"\\t\\t\\tcurrent (e) --> '\" + e + \"'\")\n",
    "                \n",
    "                new_eandf=(e,f)  #line9a\n",
    "                printifverbose(\"\\t\\t\\tcurrent (e,f) --> ('\" + e + \"','\" + f + \"')\")\n",
    "                \n",
    "                new_phi = phi + [new_eandf] #line9b\n",
    "                printifverbose(\"\\t\\t\\tϕ' = ϕ ∪ {(e,f)}\")\n",
    "                printifverbose(\"\\t\\t\\t--> \" + str(new_phi))\n",
    "                \n",
    "                # SCORE\n",
    "                if satisfy_ext_limits(new_phi,ext_limits):  #line10\n",
    "                    SCORE=score_partial_hypothesis(cipher_text,new_phi,lm)  #line11a\n",
    "\n",
    "                ht_entry=(new_phi,SCORE)  #line11b\n",
    "                printifverbose(\"\\t\\t\\t(ϕ', SCORE(ϕ'))\")\n",
    "                printifverbose(\"\\t\\t\\t--> \" + str(ht_entry) + \"   ##Add to Ht\")\n",
    "        \n",
    "                Ht.append((ht_entry))  #line 11c\n",
    "\n",
    "                printifverbose(\"\\t\\t\\t--endInnerloop--\\n\")\n",
    "\n",
    "                \n",
    "            printifverbose(\"\\t\\tHt --> \" + str(Ht)) # + \"\\n\")\n",
    "    \n",
    "            printifverbose(\"\\t\\t--endOuterloop--\\n\")\n",
    "        \n",
    "                \n",
    "        Ht = [hist_prune(Ht,nkeep)]  #line12  ##MAKE IT A LIST\n",
    "        printifverbose(\"\\tHt after prunning --> \" + str(Ht)) # + \"\\n\")\n",
    "        \n",
    "        cardinality = cardinality + 1  #line13\n",
    "        \n",
    "        Hs=Ht  #line14\n",
    "        printifverbose(\"\\n\\tHs = Ht\\n\\tHs --> \" + str(Ht)) # + \"\\n\")\n",
    "        \n",
    "        Ht=[]  #line15\n",
    "    \n",
    "    \n",
    "        printifverbose(\"\\t--endwhile--\" + \"\\n\")\n",
    "    printifverbose(\"==endbeamsearch==\" + \"\\n\")\n",
    "    return Hs  #WINNER(Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TESTING BEAM SEARCH ON SIMPLE 1:1 SUBSITUTION CIPHER\n",
    "\n",
    "sample_text=\"burger\"\n",
    "cipher_text = sample_text.upper()\n",
    "\n",
    "s1 = get_statistics(sample_text,cipher=False)\n",
    "s2 = get_statistics(cipher_text,cipher=True)\n",
    "\n",
    "\n",
    "ss = get_sorted_syms(s1,s2)\n",
    "W=[1.0,1.0,1.0,1.0,2,3]\n",
    "new_ss=sort_by_new_extension_order(sample_text,s2['vocab'],W)\n",
    "\n",
    "KEEPS=1\n",
    "ALPHA1=\"abcdefghijklmnopqrstuvwxyz\"\n",
    "ALPHA2=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "REAL_PHI=[(a,b) for a,b in zip(ALPHA1,ALPHA2)]\n",
    "\n",
    "EXT_LIMIT=1\n",
    "KEEPS=1\n",
    "\n",
    "# print('ss: ')\n",
    "# print(ss)\n",
    "# print(\"s2['vocab']:\")\n",
    "# print(s2['vocab'])\n",
    "# print(\"\\n\")\n",
    "\n",
    "final_hs=beam_search(ss,EXT_LIMIT,s2['vocab'],KEEPS,sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXT_ORDER=get_sorted_syms(plaintxt_desc,cipher_desc)\n",
    "EXT_LIMITS=1\n",
    "NKEEP=1\n",
    "#beam_search(EXT_ORDER,EXT_LIMITS,cipher_desc['vocab'],NKEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('', ''), ('x', 'R'), ('x', 'B'), ('x', 'U'), ('x', 'G'), ('x', 'E')],\n",
       "  -4.394614)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
