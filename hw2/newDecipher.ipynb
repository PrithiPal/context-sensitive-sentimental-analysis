{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import ngram\n",
    "from ngram import *\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "import numpy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats\n",
    "\n",
    "def find_mappings(ciphertext, plaintext):\n",
    "    mappings = defaultdict(dict)\n",
    "    hypotheses = defaultdict(dict)\n",
    "    \n",
    "    for symbol in ciphertext['vocab']:\n",
    "        for letter in plaintext['vocab']:\n",
    "            hypotheses[symbol][letter] = abs(math.log((ciphertext['relative_freq'][symbol]/plaintext['relative_freq'][letter])))\n",
    "    \n",
    "    for sym in hypotheses.keys():\n",
    "        winner = sorted(hypotheses[sym].items(), key=lambda kv: kv[1])\n",
    "        mappings[sym] = winner[1][0]\n",
    "    \n",
    "    return mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['º', 'y', 'K', '§', '∏', '∑', 'æ', 'µ', 'B', 'R', 'W', '—', 'S', '\\\\', 'O', 'X', 'Ç', 'T', '≈', 'Z', 'A', '∆', '/', '^', 'L', 'Ω', 'À', 'H', 'D', 'J', '–', 'π', 'V', '“', 'Ã', 'Q', '√', 'I', 'u', 'E', '∫', '+', '‘', '£', '•', 'P', '∞', 'N', 'F', 'G', 'M', 'ƒ', '¢', 'j']\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "\n",
    "\n",
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "\n",
    "mapping = find_mappings(cipher_desc, plaintxt_desc)\n",
    "\n",
    "english_text = []\n",
    "for symbol in cipher_desc['content']:\n",
    "    english_text.append(mapping[symbol])\n",
    "decipherment = ('').join(english_text)\n",
    "#print(decipherment)\n",
    "print(cipher_desc['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = []; \n",
    "symbol_relFreq = []; \n",
    "for x, y in cipher_desc[\"relative_freq\"].items():\n",
    "    symbol_list.append(x)\n",
    "    symbol_relFreq.append(y)\n",
    "    \n",
    "index_names = {}\n",
    "for i in range(54):\n",
    "    index_names[i] = symbol_list[i]\n",
    "    \n",
    "test_data = numpy.ones((54,26))\n",
    "df = pd.DataFrame(test_data, columns = plaintxt_desc['vocab'])\n",
    "df=df.rename(index = index_names )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "freq_dict=[ (k,v) for k,v in zip(cipher_desc['frequencies'].keys(),cipher_desc['frequencies'].values())]\n",
    "sorted_freq_dict=sorted(freq_dict, key=lambda x:max([v[1] for v in freq_dict])-x[1])\n",
    "sorted_symbols=[s[0] for s in sorted_freq_dict]\n",
    "\n",
    "lm = ngram.LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'o........................o............................o...................................o............................................................o....................................o......................................o...............o...................................o......................o.o.............................o..........o.................................................o............'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_bitstring(F,cipher_text) : \n",
    "    f=F[0]\n",
    "    INITIAL_BS=['o' if f == t else '.' for t in cipher_text]\n",
    "    for f in F[1:] :\n",
    "        print(f)\n",
    "        \n",
    "    FINAL_BS=INITIAL_BS\n",
    "    \n",
    "    return \"\".join(FINAL_BS)\n",
    "convert_to_bitstring(cipher_desc['vocab'][:3],\"\".join(cipher_desc['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satisfy_ext_limits(phi_obj,nkeep) : \n",
    "    \n",
    "   # print(phi_obj)\n",
    "    l = dict([(i[0],0) for i in phi_obj])\n",
    "    for elem in phi_obj : \n",
    "        l[str(elem[0])]+=1\n",
    "   \n",
    "    n_lengths=list(filter(lambda x:x>nkeep,list(l.values())))\n",
    "   \n",
    "    if n_lengths == [] : \n",
    "        return True \n",
    "    else : \n",
    "        return False\n",
    "    \n",
    "def score_partial_hypothesis(cipher, phi,lm) :\n",
    "   \n",
    "    reverse_phi= dict([(i[1],i[0]) for i in phi ])\n",
    "    f_phi_list = [i[1] for i in phi]\n",
    "    \n",
    "    deciphered_tokens=[]\n",
    "    overall_score=0\n",
    "    for f in cipher : \n",
    "       \n",
    "        if f in f_phi_list : \n",
    "            deciphered_tokens.append(reverse_phi[str(f)])\n",
    "        else : \n",
    "            deciphered_tokens.append(\"_\")  \n",
    "        \n",
    "    \n",
    "    arg1 = \"\".join(deciphered_tokens)\n",
    "    #print('arg1 = ',arg1)\n",
    "    score = lm.score_seq(arg1)     \n",
    "    return score\n",
    "\n",
    "def hist_prune(H,nkeep) : \n",
    "\n",
    "    scores = [float(i[1]) for i in H]\n",
    "    scores_s = sorted(H,key=lambda x:x[1])\n",
    "    #print(scores_s)\n",
    "    return scores_s[-1]\n",
    "\n",
    "\n",
    "def score_beam(hs,real_phi) : \n",
    "    phi = hs[0][0]\n",
    "    score=0\n",
    "    for p in phi : \n",
    "        if p in real_phi : \n",
    "            score=score+1\n",
    "    \n",
    "    correct_ratio = score/len(phi)\n",
    "    return correct_ratio\n",
    "\n",
    "def convert_to_bitstring(f,cipher_text) : \n",
    "    return \"\".join(['o' if f == t else '.' for t in cipher_text])\n",
    "\n",
    "def calculate_maximum_context_score(cipher_text,f,W) : \n",
    "    bitstring = convert_to_bitstring(f,cipher_text)\n",
    "  #  print(bitstring)\n",
    "    contagious_o = re.findall(r'[o]+',bitstring)\n",
    "    contagious_lenghts = [len(i) for i in contagious_o]\n",
    "   # print(contagious_lenghts)\n",
    "    N=6\n",
    "    max_context=[float(len(list(filter(lambda x:x==i,contagious_lenghts)))) for i in range(N)]\n",
    "    term=np.multiply(W,max_context)\n",
    "    return sum(term)\n",
    "        \n",
    "    \n",
    "## hs=[( (A,A), (A,A) ... )]\n",
    "## W=[a,a,a,a,a,a]\n",
    "## cipher_text = \"aaaaaa\"\n",
    "def sort_by_new_extension_order(cipher_text,F,W) : \n",
    "    MC_SCORE=[]\n",
    "    \n",
    "    for f in F : \n",
    "        \n",
    "        score=calculate_maximum_context_score(cipher_text,f,W)\n",
    "        MC_SCORE.append((f,score))\n",
    "    \n",
    "    \n",
    "    return list(reversed(sorted(MC_SCORE,key=lambda x:x[1])))\n",
    "    \n",
    "    \n",
    "def get_sorted_syms(x1,x2) : \n",
    "    freq_dict=[ (k,v) for k,v in zip(x2['frequencies'].keys(),x2['frequencies'].values())]\n",
    "    sorted_freq_dict=sorted(freq_dict, key=lambda x:max([v[1] for v in freq_dict])-x[1])\n",
    "    sorted_symbols=[s[0] for s in sorted_freq_dict]\n",
    "    return sorted_symbols\n",
    "\n",
    "\n",
    "#SAMPLE_PHI=[('', ''), ('e', '—'), ('e', 'º'), ('u', 'B'), ('v', 'R')]\n",
    "#satisfy_ext_limits(SAMPLE_PHI,3)\n",
    "\n",
    "\n",
    "#PHI=[('b','B')]\n",
    "#score_partial_hypothesis(\"BURGER\",PHI,lm)\n",
    "\n",
    "#SAMPLE=[([('', ''), ('e', 'O'), ('h', 'T')], -32.71637948), ([('', ''), ('e', 'O'), ('s', 'T')], -21.396480099999998), ([('', ''), ('e', 'O'), ('o', 'T')], -39.44501403), ([('', ''), ('e', 'O'), ('j', 'T')], -33.47798432999999), ([('', ''), ('e', 'O'), ('d', 'T')], -20.987173), ([('', ''), ('e', 'O'), ('v', 'T')], -30.673667710000004), ([('', ''), ('e', 'O'), ('g', 'T')], -29.781602661000004), ([('', ''), ('e', 'O'), ('f', 'T')], -28.604963550999997), ([('', ''), ('e', 'O'), ('a', 'T')], -29.75088907), ([('', ''), ('e', 'O'), ('r', 'T')], -24.553558436), ([('', ''), ('e', 'O'), ('x', 'T')], -32.67641992), ([('', ''), ('e', 'O'), ('m', 'T')], -30.1644232), ([('', ''), ('e', 'O'), ('t', 'T')], -29.95256448), ([('', ''), ('e', 'O'), ('b', 'T')], -26.972342800000003), ([('', ''), ('e', 'O'), ('u', 'T')], -34.10374856), ([('', ''), ('e', 'O'), ('c', 'T')], -33.261454670000006), ([('', ''), ('e', 'O'), ('p', 'T')], -29.9686529), ([('', ''), ('e', 'O'), ('q', 'T')], -38.0978153), ([('', ''), ('e', 'O'), ('w', 'T')], -31.314459720000002), ([('', ''), ('e', 'O'), ('k', 'T')], -29.489249459999996), ([('', ''), ('e', 'O'), ('n', 'T')], -27.4332253), ([('', ''), ('e', 'O'), ('z', 'T')], -31.70670717), ([('', ''), ('e', 'O'), ('i', 'T')], -30.30622924), ([('', ''), ('e', 'O'), ('y', 'T')], -32.38038479), ([('', ''), ('e', 'O'), ('l', 'T')], -26.465809439999997)]\n",
    "#hist_prune(SAMPLE,1)\n",
    "\n",
    "#SAMPLE= [([('', ''), ('x', 'E'), ('i', 'T'), ('a', 'N'), ('s', 'A'), ('m', 'O'), ('e', 'R'), ('j', 'U'), ('n', 'B'), ('t', 'D'), ('o', 'P'), ('r', 'I'), ('u', 'H'), ('g', 'L'), ('f', 'S'), ('q', 'Y'), ('h', 'X'), ('y', 'G'), ('b', 'W'), ('p', 'V'), ('d', 'M')], -291.5569235510001)]\n",
    "\n",
    "#CIPHER=\"\".join(cipher_desc['content'])\n",
    "#W=[1,1,1,1,2,3]\n",
    "#print(sort_by_new_extension_order(CIPHER,cipher_desc['vocab'],W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def beam_search(ext_order, ext_limits,Vf,nkeep,cipher_text):\n",
    "    Hs = []\n",
    "    Ht = []\n",
    "    cardinality = 0\n",
    "    Hs.append(([('','')],0))\n",
    "    Ve = plaintxt_desc['vocab']\n",
    "    new_phi=[]\n",
    "    \n",
    "    while cardinality < len(Vf) - 1:\n",
    "        print(\"l1-----\")\n",
    "        f = ext_order[cardinality]\n",
    "        print(\"Hs = \",Hs)\n",
    "        #print(\"Ht = \",Ht)\n",
    "        for h in Hs:\n",
    "            print(\"\\tl2-----\")\n",
    "            phi=h[0]\n",
    "            for e in Ve:\n",
    "                print(\"\\t\\tl3------\")\n",
    "                for p in phi : \n",
    "                    new_phi.append(p)\n",
    "                new_phi.append((e,f))\n",
    "                #print('newphi={}'.format(new_phi))\n",
    "                \n",
    "                if satisfy_ext_limits(new_phi,ext_limits):\n",
    "                    SCORE=score_partial_hypothesis(cipher_text,new_phi,lm)\n",
    "                    Ht.append((new_phi,SCORE))\n",
    "                new_phi=[]\n",
    "        \n",
    "        #print(\"Ht = \",Ht)   \n",
    "        \n",
    "        \n",
    "        Ht = hist_prune(Ht,nkeep)\n",
    "       # Hs=[Ht]\n",
    "        Hs.append(Ht)\n",
    "        Ht=[]\n",
    "        cardinality = cardinality + 1\n",
    "    return Hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1-----\n",
      "Hs =  [([('', '')], 0)]\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "l1-----\n",
      "Hs =  [([('', '')], 0), ([('', ''), ('j', 'R')], -4.394614)]\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "l1-----\n",
      "Hs =  [([('', '')], 0), ([('', ''), ('j', 'R')], -4.394614), ([('', ''), ('j', 'R'), ('i', 'B')], -4.394614)]\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "l1-----\n",
      "Hs =  [([('', '')], 0), ([('', ''), ('j', 'R')], -4.394614), ([('', ''), ('j', 'R'), ('i', 'B')], -4.394614), ([('', ''), ('j', 'R'), ('i', 'B'), ('e', 'U')], -4.394614)]\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\tl2-----\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n",
      "\t\tl3------\n"
     ]
    }
   ],
   "source": [
    "## TESTING BEAM SEARCH ON SIMPLE 1:1 SUBSITUTION CIPHER\n",
    "\n",
    "sample_text=\"burger\"\n",
    "cipher_text = sample_text.upper()\n",
    "\n",
    "s1 = get_statistics(sample_text,cipher=False)\n",
    "s2 = get_statistics(cipher_text,cipher=True)\n",
    "\n",
    "\n",
    "ss = get_sorted_syms(s1,s2)\n",
    "W=[1.0,1.0,1.0,1.0,2,3]\n",
    "new_ss=sort_by_new_extension_order(sample_text,s2['vocab'],W)\n",
    "\n",
    "KEEPS=1\n",
    "ALPHA1=\"abcdefghijklmnopqrstuvwxyz\"\n",
    "ALPHA2=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "REAL_PHI=[(a,b) for a,b in zip(ALPHA1,ALPHA2)]\n",
    "\n",
    "EXT_LIMIT=1\n",
    "KEEPS=1\n",
    "\n",
    "final_hs=beam_search(ss,EXT_LIMIT,s2['vocab'],KEEPS,sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXT_ORDER=get_sorted_syms(plaintxt_desc,cipher_desc)\n",
    "EXT_LIMITS=1\n",
    "NKEEP=1\n",
    "#beam_search(EXT_ORDER,EXT_LIMITS,cipher_desc['vocab'],NKEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('', '')], 0),\n",
       " ([('', ''), ('j', 'R')], -4.394614),\n",
       " ([('', ''), ('j', 'R'), ('i', 'B')], -4.394614),\n",
       " ([('', ''), ('j', 'R'), ('i', 'B'), ('e', 'U')], -4.394614),\n",
       " ([('', ''), ('j', 'R'), ('i', 'B'), ('e', 'U'), ('q', 'G')], -4.394614)]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
