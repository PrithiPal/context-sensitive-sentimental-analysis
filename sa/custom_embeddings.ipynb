{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_embeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZuyCaw_i9P9h",
        "colab_type": "code",
        "outputId": "27bf7169-eee0-4a1f-dc77-21bca0dc30b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "cell_type": "code",
      "source": [
        "## INSPIRED FROM THE https://github.com/cmasch/word-embeddings-from-scratch/blob/master/Create_Embeddings.ipynb\n",
        "\n",
        "\n",
        "!pip install gensim \n",
        "!pip install pandas\n",
        "import gensim, logging, os, re, string, tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "from gensim.utils import simple_preprocess\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "print('gensim version: \\t%s'     % gensim.__version__)\n",
        "print('TensorFlow version: \\t%s' % tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 16.7MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/b9/7df67f1775d240ac8d111211f967fa75ecc9968ae79ffa0594e36345445f/boto3-1.9.62-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.8MB/s \n",
            "\u001b[?25hCollecting botocore<1.13.0,>=1.12.62 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/77/35e82076e3beb506280f94213a258819378115f174e516ce69b3a2336e1c/botocore-1.12.62-py2.py3-none-any.whl (5.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.1MB 7.0MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.62->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 26.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.62 botocore-1.12.62 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
            "gensim version: \t3.6.0\n",
            "TensorFlow version: \t1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJ33LQ0F-0dc",
        "colab_type": "code",
        "outputId": "b9f659b3-6fbe-4f8b-cbf2-a64dd75ae5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare_movie_dataset(train_start,train_end,test_start,test_end) : \n",
        "\n",
        "    dataset = pd.read_csv('movie_reviews.csv')\n",
        "    print('dataset size : ',dataset.shape[0])\n",
        "\n",
        "    train_data = dataset[train_start:train_end]\n",
        "    test_data = dataset[test_start:test_end]\n",
        "    \n",
        "    print('Train_X : ',train_data.shape[0])\n",
        "    print('Test_X  : ',test_data.shape[0])\n",
        "\n",
        "    test_reviews = np.array(test_data['review'])\n",
        "    test_sentiments = np.array(test_data['sentiment'])\n",
        "    train_reviews=np.array(train_data['review'])\n",
        "    return train_reviews,test_reviews,test_sentiments\n",
        "\n",
        "train_x,test_x,test_y=prepare_movie_dataset(0,50000,1,2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset size :  50000\n",
            "Train_X :  50000\n",
            "Test_X  :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N3ZpRtzx9V4W",
        "colab_type": "code",
        "outputId": "1a1adc8d-7ede-4546-ce28-dbad1af2c602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3301
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# For displaying gensim logs\n",
        "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "\n",
        "EMBEDDING_SIZE = 300\n",
        "\n",
        "\n",
        "model = gensim.models.Word2Vec(train_x, size=EMBEDDING_SIZE)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO : collecting all words and their counts\n",
            "WARNING : Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO : PROGRESS: at sentence #10000, processed 13091245 words, keeping 164 word types\n",
            "INFO : PROGRESS: at sentence #20000, processed 26189472 words, keeping 175 word types\n",
            "INFO : PROGRESS: at sentence #30000, processed 39271702 words, keeping 180 word types\n",
            "INFO : PROGRESS: at sentence #40000, processed 52320923 words, keeping 192 word types\n",
            "INFO : collected 206 word types from a corpus of 65471551 raw words and 50000 sentences\n",
            "INFO : Loading a fresh vocabulary\n",
            "INFO : effective_min_count=5 retains 160 unique words (77% of original 206, drops 46)\n",
            "INFO : effective_min_count=5 leaves 65471467 word corpus (99% of original 65471551, drops 84)\n",
            "INFO : deleting the raw counts dictionary of 206 items\n",
            "INFO : sample=0.001 downsamples 31 most-common words\n",
            "INFO : downsampling leaves estimated 14234449 word corpus (21.7% of prior 65471467)\n",
            "INFO : estimated required memory for 160 words and 300 dimensions: 464000 bytes\n",
            "INFO : resetting layer weights\n",
            "INFO : training model with 3 workers on 160 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "INFO : EPOCH 1 - PROGRESS: at 3.29% examples, 457273 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 6.50% examples, 460408 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 9.73% examples, 460151 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 12.87% examples, 459985 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 16.16% examples, 459984 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 19.42% examples, 459837 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 22.52% examples, 459561 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 25.85% examples, 459654 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 29.08% examples, 459720 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 32.28% examples, 459408 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 35.62% examples, 459505 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 38.90% examples, 459286 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 42.00% examples, 459279 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 45.22% examples, 459328 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 48.45% examples, 458762 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 51.54% examples, 458148 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 54.83% examples, 457995 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 58.11% examples, 458153 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 61.23% examples, 457672 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 64.35% examples, 457121 words/s, in_qsize 5, out_qsize 1\n",
            "INFO : EPOCH 1 - PROGRESS: at 67.65% examples, 456863 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 70.80% examples, 456606 words/s, in_qsize 5, out_qsize 1\n",
            "INFO : EPOCH 1 - PROGRESS: at 74.01% examples, 456401 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 77.21% examples, 456350 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 80.49% examples, 456325 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 83.74% examples, 456246 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 86.77% examples, 456184 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 89.94% examples, 456162 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 93.21% examples, 456258 words/s, in_qsize 6, out_qsize 1\n",
            "INFO : EPOCH 1 - PROGRESS: at 96.45% examples, 456344 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 1 - PROGRESS: at 99.74% examples, 456466 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "INFO : EPOCH - 1 : training on 65471551 raw words (14234576 effective words) took 31.2s, 456364 effective words/s\n",
            "INFO : EPOCH 2 - PROGRESS: at 3.32% examples, 461730 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 6.53% examples, 461030 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 9.73% examples, 459406 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 12.88% examples, 459186 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 16.13% examples, 457904 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 19.38% examples, 457590 words/s, in_qsize 4, out_qsize 1\n",
            "INFO : EPOCH 2 - PROGRESS: at 22.46% examples, 456709 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 25.76% examples, 456858 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 28.96% examples, 457026 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 32.21% examples, 457419 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 35.51% examples, 457370 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 38.81% examples, 457515 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 41.94% examples, 457521 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 45.12% examples, 457356 words/s, in_qsize 6, out_qsize 1\n",
            "INFO : EPOCH 2 - PROGRESS: at 48.38% examples, 457485 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 51.51% examples, 457235 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 54.76% examples, 456683 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 57.97% examples, 456096 words/s, in_qsize 5, out_qsize 3\n",
            "INFO : EPOCH 2 - PROGRESS: at 61.11% examples, 455878 words/s, in_qsize 6, out_qsize 1\n",
            "INFO : EPOCH 2 - PROGRESS: at 64.25% examples, 455592 words/s, in_qsize 5, out_qsize 1\n",
            "INFO : EPOCH 2 - PROGRESS: at 67.51% examples, 455294 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 70.67% examples, 455119 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 73.84% examples, 454764 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 77.01% examples, 454581 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 80.26% examples, 454439 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 83.46% examples, 454199 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 86.52% examples, 454389 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 89.71% examples, 454558 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 93.02% examples, 454800 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 96.20% examples, 454814 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 2 - PROGRESS: at 99.54% examples, 454982 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "INFO : EPOCH - 2 : training on 65471551 raw words (14236703 effective words) took 31.3s, 454855 effective words/s\n",
            "INFO : EPOCH 3 - PROGRESS: at 3.32% examples, 461845 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 6.52% examples, 460875 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 9.75% examples, 460846 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 12.88% examples, 459080 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 16.17% examples, 458915 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 19.42% examples, 458601 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 22.54% examples, 458654 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 25.86% examples, 458938 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 29.08% examples, 459076 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 32.29% examples, 459104 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 35.59% examples, 458743 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 38.78% examples, 457877 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 41.82% examples, 456736 words/s, in_qsize 6, out_qsize 1\n",
            "INFO : EPOCH 3 - PROGRESS: at 44.95% examples, 456098 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 48.10% examples, 455276 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 51.27% examples, 455100 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 54.59% examples, 455156 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 57.72% examples, 454912 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 60.90% examples, 454734 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 64.03% examples, 454563 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 67.27% examples, 454444 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 70.45% examples, 454266 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 73.62% examples, 454063 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 76.85% examples, 454098 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 80.07% examples, 454086 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 83.33% examples, 454015 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 86.39% examples, 454016 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 89.52% examples, 454159 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 92.78% examples, 454333 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 96.03% examples, 454557 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 3 - PROGRESS: at 99.32% examples, 454596 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "INFO : EPOCH - 3 : training on 65471551 raw words (14237525 effective words) took 31.3s, 454511 effective words/s\n",
            "INFO : EPOCH 4 - PROGRESS: at 3.27% examples, 457459 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 6.47% examples, 458100 words/s, in_qsize 6, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 9.64% examples, 456980 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 12.77% examples, 457125 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 15.95% examples, 455082 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 19.19% examples, 455716 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 22.37% examples, 455892 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 25.63% examples, 456237 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 28.85% examples, 456596 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 32.09% examples, 456798 words/s, in_qsize 4, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 35.44% examples, 457251 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 38.70% examples, 457294 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 41.86% examples, 457470 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 45.05% examples, 457606 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 48.34% examples, 457726 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 51.49% examples, 457840 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 54.82% examples, 457968 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 58.08% examples, 457956 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 61.28% examples, 458085 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 64.48% examples, 458329 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 67.82% examples, 458368 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 70.97% examples, 458333 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 74.25% examples, 458514 words/s, in_qsize 6, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 77.49% examples, 458453 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 80.79% examples, 458464 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 84.06% examples, 458497 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 87.14% examples, 458588 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 90.33% examples, 458552 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 4 - PROGRESS: at 93.56% examples, 458444 words/s, in_qsize 6, out_qsize 1\n",
            "INFO : EPOCH 4 - PROGRESS: at 96.79% examples, 458456 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "INFO : EPOCH - 4 : training on 65471551 raw words (14233170 effective words) took 31.1s, 458303 effective words/s\n",
            "INFO : EPOCH 5 - PROGRESS: at 3.29% examples, 458076 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 6.45% examples, 456229 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 9.66% examples, 457173 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 12.82% examples, 457917 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 16.11% examples, 457996 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 19.38% examples, 458695 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 22.49% examples, 458639 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 25.80% examples, 458426 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 28.99% examples, 458685 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 32.16% examples, 457866 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 35.47% examples, 457716 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 38.73% examples, 457664 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 41.88% examples, 457754 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 45.05% examples, 457561 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 48.29% examples, 457378 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 51.44% examples, 457421 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 54.73% examples, 457238 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 57.97% examples, 457193 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 61.16% examples, 457221 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 64.28% examples, 456891 words/s, in_qsize 4, out_qsize 1\n",
            "INFO : EPOCH 5 - PROGRESS: at 67.61% examples, 456911 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 70.80% examples, 456905 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 74.03% examples, 456820 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 77.26% examples, 456781 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 80.52% examples, 456768 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 83.76% examples, 456733 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 86.82% examples, 456753 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 89.96% examples, 456628 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 93.23% examples, 456726 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 96.45% examples, 456653 words/s, in_qsize 5, out_qsize 0\n",
            "INFO : EPOCH 5 - PROGRESS: at 99.74% examples, 456602 words/s, in_qsize 4, out_qsize 1\n",
            "INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "INFO : EPOCH - 5 : training on 65471551 raw words (14232761 effective words) took 31.2s, 456527 effective words/s\n",
            "INFO : training on a 327357755 raw words (71174735 effective words) took 156.1s, 455981 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKpeLqMH_PoV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "HKbyX8GM9TUd",
        "colab_type": "code",
        "outputId": "9aa28eaa-3aa3-4099-acd1-2ca56c49a1e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-904fd1c79778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'Word2VecVocab' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qH_iyCUsAegE",
        "colab_type": "code",
        "outputId": "618b9e16-bdd9-4949-b143-f4ec7a63df09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "weights     = model.wv.vectors\n",
        "index_words = model.wv.index2word\n",
        "\n",
        "vocab_size    = weights.shape[0]\n",
        "embedding_dim = weights.shape[1]\n",
        "\n",
        "print('Shape of weights:', weights.shape)\n",
        "print('Vocabulary size: %i' % vocab_size)\n",
        "print('Embedding size: %i'  % embedding_dim)\n",
        "\n",
        "## WRITE THE METADATA TO .TSV FILES\n",
        "\n",
        "MODEL_DIR='.'\n",
        "with open(os.path.join('metadata.tsv'), 'w') as f:\n",
        "    f.writelines(\"\\n\".join(index_words))\n",
        "\n",
        "# Required if you re-run without restarting the kernel\n",
        "tf.reset_default_graph()\n",
        "    \n",
        "W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]), trainable=False, name=\"W\")\n",
        "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
        "\n",
        "embedding_init = W.assign(embedding_placeholder)\n",
        "writer = tf.summary.FileWriter(MODEL_DIR, graph=tf.get_default_graph())\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = W.name\n",
        "embedding.metadata_path = './metadata.tsv'\n",
        "projector.visualize_embeddings(writer, config)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(embedding_init, feed_dict={embedding_placeholder: weights})\n",
        "    save_path = saver.save(sess, os.path.join(MODEL_DIR, \"model.cpkt\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of weights: (160, 300)\n",
            "Vocabulary size: 160\n",
            "Embedding size: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-fUNpYP1Lfzk",
        "colab_type": "code",
        "outputId": "ca2da6a6-f549-40f8-81bd-bdef7a20081b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir('.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " '.ipynb_checkpoints',\n",
              " 'movie_reviews.csv',\n",
              " 'emb_yelp',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "ZfHIK1IPBDuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.wv.most_similar(positive=['coffee'], topn=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6t_ViQlBGBm",
        "colab_type": "code",
        "outputId": "157b9ed2-b6d5-4c8f-c733-e8b274244f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "cell_type": "code",
      "source": [
        "## CONVERT THE BINARY TO THE TEXT FILE\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('word2vec.bin', binary=True)\n",
        "model.save_word2vec_format('word2vec.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO : loading projection weights from word2vec.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ee9723954664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36many2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BDOzd0W2H5aC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}