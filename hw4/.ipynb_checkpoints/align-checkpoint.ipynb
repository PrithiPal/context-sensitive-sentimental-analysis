{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import optparse, sys, os, logging\n",
    "from collections import defaultdict\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with Dice's coefficient..."
     ]
    }
   ],
   "source": [
    "optparser = optparse.OptionParser()\n",
    "optparser.add_option(\"-d\", \"--datadir\", dest=\"datadir\", default=\"data\", help=\"data directory (default=data)\")\n",
    "optparser.add_option(\"-p\", \"--prefix\", dest=\"fileprefix\", default=\"hansards\", help=\"prefix of parallel data files (default=hansards)\")\n",
    "optparser.add_option(\"-e\", \"--english\", dest=\"english\", default=\"en\", help=\"suffix of English (target language) filename (default=en)\")\n",
    "optparser.add_option(\"-f\", \"--french\", dest=\"french\", default=\"fr\", help=\"suffix of French (source language) filename (default=fr)\")\n",
    "optparser.add_option(\"-l\", \"--logfile\", dest=\"logfile\", default=None, help=\"filename for logging output\")\n",
    "optparser.add_option(\"-t\", \"--threshold\", dest=\"threshold\", default=0.5, type=\"float\", help=\"threshold for alignment (default=0.5)\")\n",
    "\n",
    "SAMPLE_SENTS=1000\n",
    "#SAMPLE_SENTS=sys.maxsize\n",
    "optparser.add_option(\"-n\", \"--num_sentences\", dest=\"num_sents\", default=SAMPLE_SENTS, type=\"int\", help=\"Number of sentences to use for training and alignment\")\n",
    "(opts, _) = optparser.parse_args()\n",
    "f_data = \"%s.%s\" % (os.path.join(opts.datadir, opts.fileprefix), \"fr\")\n",
    "e_data = \"%s.%s\" % (os.path.join(opts.datadir, opts.fileprefix), \"en\")\n",
    "\n",
    "if opts.logfile:\n",
    "    logging.basicConfig(filename=opts.logfile, filemode='w', level=logging.INFO)\n",
    "\n",
    "sys.stderr.write(\"Training with Dice's coefficient...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE : WORD ALIGNMENT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 0 ..... \n",
      " Iteration 1 ..... \n",
      " Iteration 2 ..... \n",
      " Iteration 3 ..... \n",
      " Iteration 4 ..... \n"
     ]
    }
   ],
   "source": [
    "bitext = [[sentence.strip().split() for sentence in pair] for pair in islice(zip(open(f_data), open(e_data)), opts.num_sents)]\n",
    "e_count = defaultdict(int)\n",
    "fe_count = defaultdict(int)\n",
    "t = defaultdict(int)\n",
    "## INITIALIZE T_0\n",
    "for (n, (f, e)) in enumerate(bitext):\n",
    "    \n",
    "    for fi in f : \n",
    "        for ej in e : \n",
    "            #sys.stderr.write('{} -> {} \\n'.format(fi,ej))\n",
    "            t[(fi,ej)]=1/len(f)\n",
    "                \n",
    "k=0\n",
    "IND=5\n",
    "while k<IND : \n",
    "    print(' Iteration {} ..... '.format(k))\n",
    "    k+=1\n",
    "    for (n, (f, e)) in enumerate(bitext):\n",
    "        for fi in f : \n",
    "            z=0\n",
    "            for ej in e:\n",
    "                z+=t[(fi,ej)]\n",
    "            for ej in e:\n",
    "                c=t[(fi,ej)]/z\n",
    "                \n",
    "                count_fe=fe_count[(fi,ej)]\n",
    "                if count_fe not in fe_count:\n",
    "                    fe_count[(fi,ej)]=1\n",
    "                else:\n",
    "                    fe_count[(fi,ej)]+=c\n",
    "                count_e=e_count[(fi,ej)]\n",
    "                if count_e not in e_count:\n",
    "                    e_count[(fi,ej)]=1\n",
    "                else:\n",
    "                    e_count[(fi,ej)]+=c\n",
    "                    \n",
    "             \n",
    "                    \n",
    "    for (f,e) in t : \n",
    "        t[(f,e)]=fe_count[(f,e)]/e_count[(f,e)]\n",
    "        \n",
    "print('Training Finished.')\n",
    "## FINDING THE BEST ALIGNMENT\n",
    "print('Finding best alignments')\n",
    "ARGMAX_ALIGN=[]\n",
    "for (n, (f, e)) in enumerate(bitext):\n",
    "    for fi in f  :\n",
    "        bestp=0\n",
    "        bestj=0\n",
    "        for ej in e:\n",
    "            t[(fi,ej)]>bestp:\n",
    "                bestp=t([fi,ej])\n",
    "                bestj=j\n",
    "                \n",
    "        ARGMAX_ALIGN.append((fi,bestj))\n",
    "        \n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
