{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Competitive Grammar Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcfg_parse_gen import Pcfg, PcfgGenerator, CkyParse\n",
    "import nltk\n",
    "\n",
    "def print_tree(tree_string):\n",
    "    tree_string = tree_string.strip()\n",
    "    tree = nltk.Tree.fromstring(tree_string)\n",
    "    tree.pretty_print()\n",
    "\n",
    "def draw_tree(tree_string):\n",
    "    tree_string = tree_string.strip()\n",
    "    tree = nltk.Tree.fromstring(tree_string)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing sentences with your grammar\n",
    "\n",
    "While you are developing your grammar you should parse with your grammar both example sentences and samples from your and other grammars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#reading grammar file: S1.gr\n",
      "#reading grammar file: S2.gr\n",
      "#reading grammar file: Vocab.gr\n"
     ]
    }
   ],
   "source": [
    "parse_gram = Pcfg([\"S1.gr\",\"S2.gr\",\"Vocab.gr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (S1 (NP (Proper Arthur) ) (_VP (VP (VerbT is) (NP (Det the) (Nbar (Noun king) ))) (Punc .))) )\n",
      "-cross entropy: -3.7863679540999504\n",
      "             TOP              \n",
      "              |                \n",
      "              S1              \n",
      "   ___________|___             \n",
      "  |              _VP          \n",
      "  |            ___|________    \n",
      "  |           VP           |  \n",
      "  |       ____|___         |   \n",
      "  |      |        NP       |  \n",
      "  |      |     ___|___     |   \n",
      "  NP     |    |      Nbar  |  \n",
      "  |      |    |       |    |   \n",
      "Proper VerbT Det     Noun Punc\n",
      "  |      |    |       |    |   \n",
      "Arthur   is  the     king  .  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#parsing: ['Arthur', 'is', 'the', 'king', '.']\n",
      "#-cross entropy (bits/word): -3.78637\n"
     ]
    }
   ],
   "source": [
    "parser = CkyParse(parse_gram, beamsize=0.00001)\n",
    "ce, trees = parser.parse_sentences([\"Arthur is the king .\"])\n",
    "print(\"-cross entropy: {}\".format(ce))\n",
    "for tree_string in trees:\n",
    "    print_tree(tree_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (S2 (_Misc (Misc five) (_Misc (Misc strangers) (_Misc (Misc are) (_Prep (Prep at) (_Det (Det the) (_Misc (Misc (_Round Round) (_Table Table)) (_Misc (Misc .) ))))))) ) )\n",
      "-cross entropy: -9.807330330570931\n",
      "        TOP                                             \n",
      "         |                                               \n",
      "         S2                                             \n",
      "         |                                               \n",
      "       _Misc                                            \n",
      "  _______|_______                                        \n",
      " |             _Misc                                    \n",
      " |        _______|__________                             \n",
      " |       |                _Misc                         \n",
      " |       |        __________|_____                       \n",
      " |       |       |              _Prep                   \n",
      " |       |       |     ___________|_____                 \n",
      " |       |       |    |                _Det             \n",
      " |       |       |    |      ___________|_____           \n",
      " |       |       |    |     |               _Misc       \n",
      " |       |       |    |     |            _____|______    \n",
      " |       |       |    |     |          Misc        _Misc\n",
      " |       |       |    |     |      _____|_____       |   \n",
      "Misc    Misc    Misc Prep  Det  _Round      _Table  Misc\n",
      " |       |       |    |     |     |           |      |   \n",
      "five strangers  are   at   the  Round       Table    .  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#parsing: ['five', 'strangers', 'are', 'at', 'the', 'Round', 'Table', '.']\n",
      "#-cross entropy (bits/word): -9.80733\n"
     ]
    }
   ],
   "source": [
    "ce, trees = parser.parse_sentences([\"five strangers are at the Round Table .\"])\n",
    "print(\"-cross entropy: {}\".format(ce))\n",
    "for tree_string in trees:\n",
    "    print_tree(tree_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `parse_file` to parse a file of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP (S1 (NP (Proper Arthur) ) (_VP (VP (VerbT is) (NP (Det the) (Nbar (Noun king) ))) (Punc .))) )\n",
      "(TOP (S1 (NP (Proper Arthur) ) (_VP (VP (VerbT rides) (NP (Det the) (Nbar (Nbar (Noun horse) ) (PP (Prep near) (NP (Det the) (Nbar (Noun castle) )))))) (Punc .))) )\n",
      "(TOP (S2 (_Misc (Misc riding) (_Misc (Misc to) (_Misc (Misc Camelot) (_VerbT (VerbT is) (_Misc (Misc hard) (_Misc (Misc .) )))))) ) )\n",
      "(TOP (S2 (_Misc (Misc do) (_Misc (Misc coconuts) (_Misc (Misc speak) (_Misc (Misc ?) )))) ) )\n",
      "(TOP (S2 (_Misc (Misc what) (_Misc (Misc does) (_Proper (Proper Arthur) (_Misc (Misc ride) (_Misc (Misc ?) ))))) ) )\n",
      "(TOP (S2 (_Misc (Misc who) (_Misc (Misc does) (_Proper (Proper Arthur) (_Misc (Misc suggest) (_Misc (Misc she) (_Misc (Misc carry) (_Misc (Misc ?) ))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc why) (_Misc (Misc does) (_Misc (Misc England) (_Misc (Misc have) (_Det (Det a) (_Noun (Noun king) (_Misc (Misc ?) ))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc are) (_Misc (Misc they) (_Misc (Misc suggesting) (_Proper (Proper Arthur) (_Misc (Misc ride) (_Misc (Misc to) (_Misc (Misc Camelot) (_Misc (Misc ?) )))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc five) (_Misc (Misc strangers) (_Misc (Misc are) (_Prep (Prep at) (_Det (Det the) (_Misc (Misc (_Round Round) (_Table Table)) (_Misc (Misc .) ))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Guinevere) (_Misc (Misc might) (_Misc (Misc have) (_Misc (Misc known) (_Misc (Misc .) ))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Guinevere) (_Misc (Misc should) (_Misc (Misc be) (_Misc (Misc riding) (_Prep (Prep with) (_Proper (Proper Patsy) (_Misc (Misc .) ))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc it) (_VerbT (VerbT is) (_Proper (Proper (_Sir Sir) (_Lancelot Lancelot)) (_Misc (Misc who) (_Misc (Misc knows) (_Proper (Proper Zoot) (_Misc (Misc !) ))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc either) (_Proper (Proper Arthur) (_Misc (Misc knows) (_Misc (Misc or) (_Proper (Proper Patsy) (_Misc (Misc does) (_Misc (Misc .) ))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc neither) (_Proper (Proper (_Sir Sir) (_Lancelot Lancelot)) (_Misc (Misc nor) (_Proper (Proper Guinevere) (_Misc (Misc will) (_Misc (Misc speak) (_Prep (Prep of) (_Misc (Misc it) (_Misc (Misc .) ))))))))) ) )\n",
      "(TOP (S2 (_Det (Det the) (_Misc (Misc (_Holy Holy) (_Grail Grail)) (_Misc (Misc was) (_Misc (Misc covered) (_Prep (Prep by) (_Det (Det a) (_Misc (Misc yellow) (_Noun (Noun fruit) (_Misc (Misc .) ))))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Zoot) (_Misc (Misc might) (_Misc (Misc have) (_Misc (Misc been) (_Misc (Misc carried) (_Prep (Prep by) (_Det (Det a) (_Noun (Noun swallow) (_Misc (Misc .) ))))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Arthur) (_Misc (Misc rode) (_Misc (Misc to) (_Misc (Misc Camelot) (_Misc (Misc and) (_Misc (Misc drank) (_Prep (Prep from) (_Misc (Misc his) (_Noun (Noun chalice) (_Misc (Misc .) )))))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc they) (_Misc (Misc migrate) (_Misc (Misc precisely) (_Misc (Misc because) (_Misc (Misc they) (_Misc (Misc know) (_Misc (Misc they) (_Misc (Misc will) (_Misc (Misc grow) (_Misc (Misc .) )))))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc do) (_Misc (Misc not) (_Misc (Misc speak) (_Misc (Misc !) )))) ) )\n",
      "(TOP (S2 (_Proper (Proper Arthur) (_Misc (Misc will) (_Misc (Misc have) (_Misc (Misc been) (_Misc (Misc riding) (_Prep (Prep for) (_Misc (Misc eight) (_Misc (Misc nights) (_Misc (Misc .) ))))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Arthur) (_Misc (Misc ,) (_Misc (Misc sixty) (_Misc (Misc inches) (_Misc (Misc ,) (_VerbT (VerbT is) (_Det (Det a) (_Misc (Misc tiny) (_Noun (Noun king) (_Misc (Misc .) )))))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Arthur) (_Misc (Misc knows) (_Proper (Proper Patsy) (_Misc (Misc ,) (_Det (Det the) (_Misc (Misc trusty) (_Noun (Noun servant) (_Misc (Misc .) )))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Arthur) (_Misc (Misc and) (_Proper (Proper Guinevere) (_Misc (Misc migrate) (_Misc (Misc frequently) (_Misc (Misc .) )))))) ) )\n",
      "(TOP (S2 (_Misc (Misc he) (_Misc (Misc knows) (_Misc (Misc what) (_Misc (Misc they) (_Misc (Misc are) (_Misc (Misc covering) (_Prep (Prep with) (_Det (Det that) (_Noun (Noun story) (_Misc (Misc .) )))))))))) ) )\n",
      "(TOP (S2 (_Proper (Proper Arthur) (_Misc (Misc suggested) (_Det (Det that) (_Det (Det the) (_Noun (Noun castle) (_Misc (Misc be) (_Misc (Misc carried) (_Misc (Misc .) )))))))) ) )\n",
      "(TOP (S2 (_Det (Det the) (_Noun (Noun king) (_Misc (Misc drank) (_Misc (Misc to) (_Det (Det the) (_Noun (Noun castle) (_Det (Det that) (_Misc (Misc was) (_Misc (Misc his) (_Noun (Noun home) (_Misc (Misc .) ))))))))))) ) )\n",
      "(TOP (S2 (_Misc (Misc when) (_Det (Det the) (_Noun (Noun king) (_VerbT (VerbT drinks) (_Misc (Misc ,) (_Proper (Proper Patsy) (_VerbT (VerbT drinks) (_Misc (Misc .) )))))))) ) )\n",
      "-cross entropy: -10.276152770660259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#parsing: ['Arthur', 'is', 'the', 'king', '.']\n",
      "#parsing: ['Arthur', 'rides', 'the', 'horse', 'near', 'the', 'castle', '.']\n",
      "#parsing: ['riding', 'to', 'Camelot', 'is', 'hard', '.']\n",
      "#parsing: ['do', 'coconuts', 'speak', '?']\n",
      "#parsing: ['what', 'does', 'Arthur', 'ride', '?']\n",
      "#parsing: ['who', 'does', 'Arthur', 'suggest', 'she', 'carry', '?']\n",
      "#parsing: ['why', 'does', 'England', 'have', 'a', 'king', '?']\n",
      "#parsing: ['are', 'they', 'suggesting', 'Arthur', 'ride', 'to', 'Camelot', '?']\n",
      "#parsing: ['five', 'strangers', 'are', 'at', 'the', 'Round', 'Table', '.']\n",
      "#parsing: ['Guinevere', 'might', 'have', 'known', '.']\n",
      "#parsing: ['Guinevere', 'should', 'be', 'riding', 'with', 'Patsy', '.']\n",
      "#parsing: ['it', 'is', 'Sir', 'Lancelot', 'who', 'knows', 'Zoot', '!']\n",
      "#parsing: ['either', 'Arthur', 'knows', 'or', 'Patsy', 'does', '.']\n",
      "#parsing: ['neither', 'Sir', 'Lancelot', 'nor', 'Guinevere', 'will', 'speak', 'of', 'it', '.']\n",
      "#parsing: ['the', 'Holy', 'Grail', 'was', 'covered', 'by', 'a', 'yellow', 'fruit', '.']\n",
      "#parsing: ['Zoot', 'might', 'have', 'been', 'carried', 'by', 'a', 'swallow', '.']\n",
      "#parsing: ['Arthur', 'rode', 'to', 'Camelot', 'and', 'drank', 'from', 'his', 'chalice', '.']\n",
      "#parsing: ['they', 'migrate', 'precisely', 'because', 'they', 'know', 'they', 'will', 'grow', '.']\n",
      "#parsing: ['do', 'not', 'speak', '!']\n",
      "#parsing: ['Arthur', 'will', 'have', 'been', 'riding', 'for', 'eight', 'nights', '.']\n",
      "#parsing: ['Arthur', ',', 'sixty', 'inches', ',', 'is', 'a', 'tiny', 'king', '.']\n",
      "#parsing: ['Arthur', 'knows', 'Patsy', ',', 'the', 'trusty', 'servant', '.']\n",
      "#parsing: ['Arthur', 'and', 'Guinevere', 'migrate', 'frequently', '.']\n",
      "#parsing: ['he', 'knows', 'what', 'they', 'are', 'covering', 'with', 'that', 'story', '.']\n",
      "#parsing: ['Arthur', 'suggested', 'that', 'the', 'castle', 'be', 'carried', '.']\n",
      "#parsing: ['the', 'king', 'drank', 'to', 'the', 'castle', 'that', 'was', 'his', 'home', '.']\n",
      "#parsing: ['when', 'the', 'king', 'drinks', ',', 'Patsy', 'drinks', '.']\n",
      "#-cross entropy (bits/word): -10.2762\n"
     ]
    }
   ],
   "source": [
    "ce, trees = parser.parse_file('example_sentences.txt')\n",
    "print(\"-cross entropy: {}\".format(ce))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences with your grammar\n",
    "\n",
    "While you are developing your grammar you should generate sentences with your grammar\n",
    "to check what your grammar is doing. Try to write your grammars to that it will \n",
    "generate hard to parse sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#reading grammar file: S1.gr\n",
      "#reading grammar file: Vocab.gr\n"
     ]
    }
   ],
   "source": [
    "gen_gram = Pcfg([\"S1.gr\",\"Vocab.gr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another sovereign has no sovereign\n",
      "Sir Knight has that weight\n",
      "any chalice is the quest\n",
      "see\n",
      "a swallow carries that coconut .\n",
      "Arthur carries Patsy\n",
      "this home carries every swallow .\n",
      "no swallow is each servant on this fruit with the pound\n",
      "no master at another land carries each horse\n",
      "that story has another sovereign .\n",
      "a castle carries no defeater .\n",
      "that story drinks Guinevere\n",
      "a castle is each coconut across any sun .\n",
      "no chalice rides no swallow\n",
      "this swallow has that winter\n",
      "another story drinks each husk into every swallow\n",
      "this winter below any coconut covers that horse .\n",
      "no servant has no sun .\n",
      "the servant is that husk on a swallow .\n",
      "that chalice carries each horse\n"
     ]
    }
   ],
   "source": [
    "gen = PcfgGenerator(gen_gram)\n",
    "for _ in range(20):\n",
    "    print(\" \".join(gen.generate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using nltk for pos tagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## CREATING NewVocab.gr\n",
    "\n",
    "## have pos for already existing tokens\n",
    "## add new tokens from allowed_words and get pos for them also.\n",
    "\n",
    "import re \n",
    "vocab_file = open(\"Vocab.gr\")\n",
    "VOCAB_RULES=[]\n",
    "new_vocab_file=open(\"NewVocab.gr\",'w')\n",
    "NEW_POS=[]\n",
    "\n",
    "NEW_POS_LINE=[]\n",
    "\n",
    "ALL_POS=[]\n",
    "\n",
    "DELIMITERS=[\" \"*i for i in range(10)]\n",
    "\n",
    "for line in vocab_file : \n",
    "    if line[0] != \"#\" and re.match(r'[0-9|\\.]',line[0]) and line[0] != \" \" : ## A VALID GRAMMAR \n",
    "            \n",
    "            REGEX=r\"([0-9]*)\\ +([A-Za-z_]*)\\ +([A-Za-z_0-9\\?\\.\\,\\'\\;'\\!\\\"\\--\\-\\:]*)\"\n",
    "            contents = re.findall(REGEX,line)[0]\n",
    "            \n",
    "            weight = contents[0]\n",
    "            original_pos = contents[1]\n",
    "            token = contents[2]\n",
    "            \n",
    "            if original_pos == \"Misc\" : \n",
    "                new_pos = nltk.pos_tag([token])[0][1]  \n",
    "                new_line=re.sub(r'Misc',new_pos,line)\n",
    "                NEW_POS.append(new_pos)\n",
    "                ALL_POS.append(new_pos)\n",
    "                #print(new_pos)\n",
    "                #print(new_line)\n",
    "                new_vocab_file.write(new_line)\n",
    "                NEW_POS_LINE.append(new_line)\n",
    "            else : \n",
    "                #print(line)\n",
    "                new_vocab_file.write(line)\n",
    "                NEW_POS_LINE.append(line)\n",
    "                ALL_POS.append(original_pos)\n",
    "    else : \n",
    "        #print(line)\n",
    "        new_vocab_file.write(line)\n",
    "        NEW_POS_LINE.append(line)\n",
    "\n",
    "\n",
    "new_vocab_file.write(\"# NEW VOCABULARY FROM allowed_words.txt\\n\")\n",
    "\n",
    "allowed_word_file = open(\"allowed_words.txt\",\"r\")       \n",
    "\n",
    "for token in allowed_word_file : \n",
    "    \n",
    "    token = token.strip()\n",
    "    pos_token = nltk.pos_tag([token])[0][1]\n",
    "    token_weight = 1\n",
    "    #print(\"{}\".format(pos_token))\n",
    "    new_vocab_file.write(\"{}   {}   {}\\n\".format(token_weight,pos_token,token))\n",
    "    \n",
    "        \n",
    "\n",
    "new_vocab_file.close()\n",
    "\n",
    "## make the set of all part of speeches \n",
    "POS_set=set(ALL_POS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- PENDING  : BIGRAM FOR S2\n",
    "\n",
    "from nltk import bigrams, trigrams \n",
    "from collections import defaultdict\n",
    "example_sents_file = open('example_sentences.txt','r')\n",
    "sent_corpus = example_sents_file.readlines()\n",
    "tokenize_text = [nltk.word_tokenize(sent) for sent in sent_corpus]\n",
    "bigram_corpus = [list(bigrams(sent)) for sent in tokenize_text]\n",
    "\n",
    "\n",
    "model = defaultdict(int)\n",
    "pos_model = defaultdict(int)\n",
    "\n",
    "\n",
    "## COMPUTING BIGRAMS\n",
    "for i in range(len(bigram_corpus)) : \n",
    "    for w1, w2 in bigram_corpus[i]:\n",
    "        model[w1,w2]+= 1\n",
    "        \n",
    "        pos_w1 = nltk.pos_tag([w1])[0][1]\n",
    "        pos_w2 = nltk.pos_tag([w2])[0][1]\n",
    "        \n",
    "        \n",
    "        ## ACTUALLY GET THE POS FROM THE VOCAB.GR\n",
    "        pos_model[pos_w1,pos_w2]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ESTIMATING SINGLE TOKEN FREQUENCIES IN example_sents_file\n",
    "## POPULATE THE df's freq from more sampling.\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "example_sents_file = open('example_sentences.txt','r')\n",
    "corpus = example_sents_file.readlines()\n",
    "tokenized_corpus = [nltk.word_tokenize(sent) for sent in corpus ]\n",
    "FLAT_TOKEN_LIST=[]\n",
    "for a in tokenized_corpus : \n",
    "    for b in a : \n",
    "        FLAT_TOKEN_LIST.append(b)\n",
    "        \n",
    "vocab_dist = FreqDist(FLAT_TOKEN_LIST)\n",
    "vocab_dist_df = pd.DataFrame(data=list(vocab_dist.values()),columns=['freq'])\n",
    "vocab_dist_df['token'] = list(vocab_dist.keys())\n",
    "vocab_dist_df['pos'] = vocab_dist_df.apply(lambda x: nltk.pos_tag([x['token']])[0][1],axis=1)\n",
    "\n",
    "total_count = vocab_dist_df['freq'].sum()\n",
    "vocab_dist_df['prob'] = vocab_dist_df.apply(lambda x: int(x['freq'])/total_count,axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING S2_new.gr\n",
    "\n",
    "\n",
    "## SCRIPT FOR NEW RULES IN S2.gr\n",
    "## THE IDEA IS TO GENERATE a -> b c \n",
    "## THE WEIGHTS ARE KEPT ONE FOR SYMPLICITY NOW.\n",
    "\n",
    "A_RULES = [\"_{}\".format(non_terminal) for non_terminal in POS_set ]\n",
    "A_RULES_SPACE = []\n",
    "A_RULES_SPACE.append(\"\")\n",
    "\n",
    "for i in range(len(A_RULES)) : \n",
    "    A_RULES_SPACE.append(A_RULES[i])\n",
    "\n",
    "\n",
    "S2_ALL_RULES=[]\n",
    "s2_new_file=open(\"S2_new.gr\",\"w\")\n",
    "\n",
    "\n",
    "for a in A_RULES : \n",
    "    s2_new_file.write(\"1\\tS2\\t{}\\n\".format(a))\n",
    "    \n",
    "## CREATE S2_new.gr with 1 a b c rules\n",
    "for a in A_RULES : \n",
    "    for b in POS_set : \n",
    "        for c in A_RULES_SPACE : \n",
    "            #print(\"1 {}\\t{}\\t{}\".format(a,b,c))\n",
    "            \n",
    "            if c == \"\" : \n",
    "                S2_ALL_RULES.append(\"1\\t{}\\t{}\\n\".format(a,b))\n",
    "                s2_new_file.write(\"1\\t{}\\t{}\\n\".format(a,b))\n",
    "            else : \n",
    "                S2_ALL_RULES.append(\"1\\t{}\\t{}\\t{}\\n\".format(a,b,c))\n",
    "                s2_new_file.write(\"1\\t{}\\t{}\\t{}\\n\".format(a,b,c))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "s2_new_file.close()\n",
    "#print(S2_ALL_RULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_vocab_weights(df,vocab_file) : \n",
    "    for line in vocab_file : \n",
    "        if line[0] != \"#\" and re.match(r'[0-9|\\.]',line[0]) and line[0] != \" \" : ## A VALID GRAMMAR \n",
    "                \n",
    "            REGEX=r\"([0-9]*)\\ +([A-Za-z_]*)\\ +([A-Za-z_0-9\\?\\.\\,\\'\\;'\\!\\\"\\--\\-\\:]*)\"\n",
    "            contents = re.findall(REGEX,line)[0]\n",
    "            \n",
    "            old_weight = contents[0]\n",
    "            original_pos = contents[1]\n",
    "            token = contents[2]\n",
    "            \n",
    "            ## SEARCH IN THE DF\n",
    "            new_weight = df[df['token']==token]['freq']\n",
    "            if new_weight is None or new_weight==0 : \n",
    "                new_weight = old_weight\n",
    "            \n",
    "            NEW_LINE = \"{}\\t{}\\t{}\"\n",
    "                \n",
    "        else : \n",
    "            \n",
    "            vocab_file.write(line)\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
