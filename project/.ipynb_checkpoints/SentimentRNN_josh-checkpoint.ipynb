{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "SWpEG0g3uvRS",
    "outputId": "909f470b-cf18-4864-f573-a975d02c2f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling HTMLParser-0.0.2:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.6/dist-packages/HTMLParser-0.0.2.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/HTMLParser.py\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled HTMLParser-0.0.2\n",
      "Collecting HTMLParser\n",
      "Installing collected packages: HTMLParser\n",
      "Successfully installed HTMLParser-0.0.2\n"
     ]
    }
   ],
   "source": [
    "# !mkdir representations\n",
    "# !mkdir representations\n",
    "# !mv representation_factory.py representations\n",
    "# !pip3 install markupbase\n",
    "# !apt-get install libmysqlclient-dev\n",
    "# !apt install default-libmysqlclient-dev\n",
    "!pip3 uninstall HTMLParser\n",
    "!pip3 install HTMLParser\n",
    "# !pip3 install rainbowstream\n",
    "# !pip3 install dynet\n",
    "# !apt-get install libmariadbclient-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "8p5DcEkLvXFS",
    "outputId": "34cb2386-ddf5-4aa9-d6b0-6812e8eed0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import itertools\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "# from normalization import normalize_accented_characters, html_parser, strip_html\n",
    "from utils import display_evaluation_metrics, display_confusion_matrix, display_classification_report\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('sentiwordnet')\n",
    "import dynet as dy\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5Qy_mJaynex"
   },
   "outputs": [],
   "source": [
    "# !mv sentiwordnet.lex lexicons_zeeyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ogmvh_wmu32W"
   },
   "outputs": [],
   "source": [
    "ZEEYANG_LEXICONS='lexicons_zeeyang'\n",
    "def read_zeeyang_lexicons(fname) : \n",
    "    \n",
    "    polarities=defaultdict()\n",
    "    for line in open(fname,'r') : \n",
    "        token=line.split(\" \")[0]\n",
    "        score=line.split(\" \")[1]\n",
    "        polarities[token]=score\n",
    "        \n",
    "    return polarities\n",
    "\n",
    "## THESE LEXICONS HAVE CONTINOUS SCORES (BETWEEN -1 AND 1 )\n",
    "# senti140_lexicons=read_zeeyang_lexicons(ZEEYANG_LEXICONS+\"/sentiment140.lex\")\n",
    "sentiwn_lexicons=read_zeeyang_lexicons(ZEEYANG_LEXICONS+\"/sentiwordnet.lex\")\n",
    "# sst_lexicons=read_zeeyang_lexicons(ZEEYANG_LEXICONS+\"/stanford.tree.lexicon\")\n",
    "\n",
    "\n",
    "## THE CODE CORRECTS THE SENTI140 and SENTIWORDNET\n",
    "\n",
    "def correct_format(lexicons) : \n",
    "    new_lexicons=defaultdict()\n",
    "    for w in lexicons: \n",
    "        score=lexicons[w]\n",
    "        score=score[:-2]\n",
    "        score=float(score)\n",
    "        new_lexicons[w]=score\n",
    "    return new_lexicons\n",
    "\n",
    "# senti140_lexicons=correct_format(senti140_lexicons)\n",
    "sentiwn_lexicons=correct_format(sentiwn_lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hus99wDJvUnu"
   },
   "outputs": [],
   "source": [
    "def calculate_new_lexicon_polarities(parent_lexicon,positive_seeds,negative_seeds,technique,embedding_type) : \n",
    "    \n",
    "    ## LOAD THE WORD-EMBEDDINGS : \n",
    "    EMBEDDEING_TYPE=''\n",
    "    if embedding_type=='GLOVE' : \n",
    "        EMBEDDING_TYPE=constants.GLOVE_EMBEDDINGS\n",
    "    elif embedding_type=='YELP' : \n",
    "        EMBEDDING_TYPE=constants.YELP_EMBEDDINGS\n",
    "        \n",
    "        \n",
    "    eval_words = set(parent_lexicon.keys())\n",
    "\n",
    "    EMBEDDING_TYPE = constants.GLOVE_EMBEDDINGS\n",
    "    EMBEDDING = create_representation(\"GIGA\", constants.GLOVE_EMBEDDINGS,eval_words.union(positive_seeds).union(negative_seeds))\n",
    "\n",
    "    embed_words = set(EMBEDDING.iw)\n",
    "    eval_words = eval_words.intersection(EMBEDDING)\n",
    "    eval_words = [word for word in eval_words  if not word in positive_seeds and not word in negative_seeds]\n",
    "\n",
    "    ## TRAIN THE BEST ALGORITHM : SENTPROP and get polarities re-scored\n",
    "    \n",
    "\n",
    "    \n",
    "    polarities=defaultdict()\n",
    "    if technique=='label_propagate_prob' : \n",
    "        \n",
    "        polarities = run_method(positive_seeds, negative_seeds, \n",
    "                    EMBEDDING.get_subembed(set(eval_words).union(negative_seeds).union(positive_seeds)),\n",
    "                    method=polarity_induction_methods.label_propagate_probabilistic,beta=0.99, nn=10)\n",
    "        \n",
    "        return polarities,eval_words\n",
    "    \n",
    "    elif technique == 'pmi' : \n",
    "        \n",
    "        #hist_words = set(hist_embed.iw)\n",
    "        #eval_words = eval_words.intersection(hist_words)\n",
    "\n",
    "        #eval_words = [word for word in eval_words if not word in positive_seeds and not word in negative_seeds] \n",
    "        print( \"Evaluating with \", len(eval_words), \"out of\", len(lexicon))\n",
    "\n",
    "        print (\"PMI\")\n",
    "        polarities = run_method(positive_seeds, \n",
    "                                negative_seeds,\n",
    "                                EMBEDDING.get_subembed(set(eval_words).union(negative_seeds).union(positive_seeds)),\n",
    "                                method=polarity_induction_methods.bootstrap,\n",
    "                                score_method=polarity_induction_methods.pmi,\n",
    "                                )\n",
    "        return polarities,eval_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edOBbI7by3qA"
   },
   "outputs": [],
   "source": [
    "POSITIVE_SE = [\"good\", \"lovely\", \"excellent\", \"fortunate\", \"pleasant\", \"delightful\", \"perfect\", \"loved\", \"love\", \"happy\"] \n",
    "NEGATIVE_SE = [\"bad\", \"horrible\", \"poor\",  \"unfortunate\", \"unpleasant\", \"disgusting\", \"evil\", \"hated\", \"hate\", \"unhappy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCedLvYuzA97"
   },
   "outputs": [],
   "source": [
    "# !mv matrix_serializer.py representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-Dd7AFrzexw"
   },
   "outputs": [],
   "source": [
    "# !mkdir example_embeddings\n",
    "# !mv glove.6B.100d.txt example_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eMA6ZvHLy6iC",
    "outputId": "99334114-10aa-446b-cfc3-87ba0ab691f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from representations.representation_factory import create_representation\n",
    "import constants\n",
    "from evaluate_methods import run_method\n",
    "import polarity_induction_methods\n",
    "\n",
    "## LABEL PROPAGATE\n",
    "## With GLOVE Embeddings\n",
    "sentiwn_polarities,swn_eval = calculate_new_lexicon_polarities(sentiwn_lexicons,POSITIVE_SE,NEGATIVE_SE,'label_propagate_prob', 'GLOVE')\n",
    "gc.collect()\n",
    "# print(type(sentiwn_polarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xipyml2Zy8_1",
    "outputId": "bb2edb72-1888-4db2-ae3e-15ef31606844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18020\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "print(len(sentiwn_polarities))\n",
    "print(len(swn_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nIvmPmVP4NSZ",
    "outputId": "b0dfbfa8-a807-4d85-f5a1-c43591d24ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trollop\n",
      "0.4998321829789092\n"
     ]
    }
   ],
   "source": [
    "print(list(sentiwn_polarities.keys())[2])\n",
    "print(sentiwn_polarities['trollop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a9E_-hEx48kB",
    "outputId": "157117cb-2b4d-4f4c-f50c-331c89f63289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trollop\n"
     ]
    }
   ],
   "source": [
    "print(swn_eval[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWuwV8u578qz"
   },
   "outputs": [],
   "source": [
    "!mv movie_reviews.csv datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YypA51qH7zaq"
   },
   "outputs": [],
   "source": [
    "def prepare_movie_dataset(train_start,train_end,test_start,test_end) : \n",
    "\n",
    "    dataset = pd.read_csv(r'datasets/movie_reviews.csv')\n",
    "    print('dataset size : ',dataset.shape[0])\n",
    "\n",
    "    train_data = dataset[train_start:train_end]\n",
    "    test_data = dataset[test_start:test_end]\n",
    "    \n",
    "    print('Train_X : ',train_data.shape[0])\n",
    "    print('Test_X  : ',test_data.shape[0])\n",
    "\n",
    "    test_reviews = np.array(test_data['review'])\n",
    "    test_sentiments = np.array(test_data['sentiment'])\n",
    "\n",
    "    return train_data,test_reviews,test_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Uiqq3AOw5QNc",
    "outputId": "f473a345-3ca9-49d7-d76e-16aedf0377d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size :  50000\n",
      "Train_X :  1000\n",
      "Test_X  :  1000\n"
     ]
    }
   ],
   "source": [
    "train_x,test_x,test_y=prepare_movie_dataset(0,1000,1000,2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26CTAI088-B3"
   },
   "source": [
    "##~~ FROM HERE NOT SURE HOW TO INTEGRATE THE CODE ABOVE BECAUSE OF DIFFERENT DATA ~~ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "butLIIh68hI-"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "vocabulary_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "okb0diCX8YVe",
    "outputId": "9739a7b4-22d1-41ea-81c8-ce032d02b56b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-04be454acdb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'review'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=max_words)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssFvIqUQ8ZD0"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Fy2Hac_9ar5"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KvC3a-Zd9chk"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4GU5kVX9eY4"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
